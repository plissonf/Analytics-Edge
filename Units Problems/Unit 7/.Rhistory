return(summary(fit)$r.square)
}
rsq
results <- boot(data=Xy, statistic=rsq,
R=1000, formula=y~X1+X2)
results
plot(results)
boot.ci(results, type="all")
fit
summary(fit)
lm.subset <- function(data,index)
{
lm.fit <- lm(y~.,data=data[index,])
beta1 <- summary(lm.fit)$coefficients[2,2]
return(beta1)
}
bs.out <- boot(data=Xy,lm.subset,R=20000)
bs.out <- boot(data=Xy,lm.subset,R=20000)
lm.subset <- function(data,index)
{
lm.fit <- lm(y~.,data=data[index,])
beta1 <- summary(lm.fit)$coefficients[2,1]
return(beta1)
}
n
s
f
lm.subset <- function(data,index)
{
lm.fit <- lm(y~.,data=data[index,])
beta1 <- summary(lm.fit)$coefficients[2,1]
return(beta1)
}
lm.fit
bs.out <- boot(data=Xy,lm.subset,R=20000)
load("~/Downloads/5.R.RData")
Xy
summary(Xy)
fit <- lm(y~X1+X2, data=Xy)
summary(fit)
coefficients(fit)
?standarderros
?se
??se
coefficients(fit)
summary(fit)
?bootstrap
??bootstrap
?boot
??boot
randomXy <- matrix( runif(3000, -1, 2), 1000, 3)
View(randomXy)
matplot(randomXy[, 1:2],type="l")
library(boot)
lm.subset <- function(data,index)
{
lm.fit <- lm(y~.,data=data[index,])
beta1 <- summary(lm.fit)$coefficients[2,1]
return(beta1)
}
results <- boot(Xy, lm.subset, R=1000)
results
lm.subset <- function(data,index)
{
lm.fit <- lm(y~.,data=data[index,])
beta1 <- summary(lm.fit)$coefficients[2,2]
return(beta1)
}
results <- boot(Xy, lm.subset, R=1000)
results
lm.subset <- function(data,index)
{
lm.fit <- lm(y~.,data=data[index,])
}
results <- boot(Xy, lm.subset, R=1000)
results
results <- boot(Xy, lm.subset, R=1000)
lm.subset <- function(data,index)
{
lm.fit <- lm(y~.,data=data[index,])
}
results <- boot(Xy, lm.subset, R=1000)
lm.subset <- function(data,indices)
{
fit <- lm(y~X1+X2,data=data[indices,])
beta1 <- coefficients(summary(fit))[2,1]
return(beta1)
}
results <- boot(Xy, lm.subset, R=1000)
results
lm.fn <- function(data,indices)
{
fit <- lm(y~X1+X2,data=data[indices,])
beta1 <- coefficients(summary(fit))[2,2]
return(beta1)
}
results <- boot(Xy, lm.fn, R=1000)
results
lm.fn <- function(data,indices)
{
fit <- lm(y~X1+X2,data=data[indices,])
beta1 <- coefficients(summary(fit))[2,2]
sd <- sd(beta1)
return(sd)
}
results <- boot(Xy, lm.fn, R=1000)
results
results
lm.fn <- function(data,indices)
{
fit <- lm(y~X1+X2,data=data[indices,])
beta1 <- coefficients(summary(fit))[2,2]
#sd <- sd(beta1)
#return(sd)
}
results <- boot(Xy, lm.fn, R=1000)
results
bs <- function(formula, data, indices) {
d <- data[indices,] # allows boot to select sample
fit <- lm(formula, data=d)
return(coef(fit))
}
results <- boot(data=Xy, statistic=bs,
R=1000, formula=y~X1+X2)
results
lm.fn <- function(data,indices)
{
fit <- lm(y~X1+X2,data=data[indices,])
coeff <- coef(fit)
#sd <- sd(beta1)
return(coeff)
}
results <- boot(Xy, lm.fn, R=1000)
results
lm.fn <- function(formula,data, indices)
{
fit <- lm(formula, data=d)
coeff <- coef(fit)
#sd <- sd(beta1)
return(coeff)
}
results <- boot(Xy, lm.fn, R=1000,formula=y~X1+X2)
results
results <- boot(data=Xy, statistic=bs,
R=1000)
bs <- function(formula, data, indices) {
d <- data[indices,] # allows boot to select sample
fit <- lm(formula, data=d)
return(coef(fit))
}
results <- boot(data=Xy, statistic=bs,
R=1000)
lm.fn <- function(formula,data, indices)
{
fit <- lm(formula, data=d)
coeff <- coef(fit)
#sd <- sd(beta1)
return(coeff)
}
results <- boot(Xy, lm.fn, R=1000,formula=y~X1+X2)
results
lm.fn <- function(formula,data, indices){
fit <- lm(y~X1+X2, data=d)
coeff <- coef(fit)
return(coeff)
}
results <- boot(data=Xy, statistic=lm.fn, R=1000)
results
results <- boot(data=Xy, statistic=lm.fn, R=1000)
library(boot)
lm.fn <- function(formula,data, indices){
fit <- lm(y~X1+X2, data=Xy)
coeff <- coef(fit)
return(coeff)
}
results <- boot(data=Xy, statistic=lm.fn, R=1000)
results
lm.fn <- function(formula, data, indices){
fit <- lm(formula,data)
coeff <- coef(fit)
return(coeff)
}
results <- boot(data=Xy, statistic=lm.fn, R=1000, formula=y~X1+X2)
results
lm.fn <- function(formula, data, indices){
d <- data[indices,]
fit <- lm(formula,data=d)
coeff <- coef(fit)
return(coeff)
}
results <- boot(data=Xy, statistic=lm.fn, R=1000, formula=y~X1+X2)
results
library(boot)
lm.fn <- function(formula, data, indices){
d <- data[indices,]
fit <- lm(formula,data=d)
coeff <- coef(fit)
return(coeff)
}
results <- boot(data=Xy, statistic=lm.fn, R=1000, formula=y~X1+X2)
results
new.rows = c(101:200, 401:500, 101:200, 901:1000, 301:400, 1:100, 1:100, 801:900, 201:300, 701:800)
new.Xy = Xy[new.rows, ]
results <- boot(data=new.Xy, statistic=lm.fn, R=1000, formula=y~X1+X2)
results
library(ISLR)
summary(Hitters)
points(10, reg.summary$cp[10], pch=20, col="red")
library(leaps)
regfit.full=regsubsets(Salary~., data=Hitters)
reg.summary=summary(regfit.full)
regfit.full=regsubsets(Salary~., data=Hitters, nvmax=19)
library(ISLR)
summary(Hitters)
```
There as some missing values here, so before we proceed we will remove them:
```{r, echo=FALSE}
Hitters = na.omit(Hitters)
with(Hitters, um(is.na(Salary)))
```
Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
```{r}
library(leaps)
regfit.full=regsubsets(Salary~., data=Hitters)
reg.summary=summary(regfit.full)
regfit.full=regsubsets(Salary~., data=Hitters, nvmax=19)
reg.summary=summary(regfit.full)
names(reg.summary)
plot(reg.summary$cp, xlab="Number of Variables", ylab="Cp")
which.min(reg.summary$cp)
points(10, reg.summary$cp[10], pch=20, col="red")
```
library(glmnet)
install.packages("glmnet")
cv.glmnet()
??cv.glmnet()
sd(c(5,8,12))
which.min(c(4,1,6))
library(readr)
library(ggmap)
install.packages(c("readr", "ggmap"))
View(new.Xy)
View(new.Xy)
View(new.Xy)
library(ggmap)
ggtitle("Distribution of Mosquito Counts (Log Scale")
library(readr)
library(ggmap)
data_dir <- "../input"
train <- read_csv(file.path(data_dir, "train.csv"))
mapdata <- readRDS(file.path(data_dir, "mapdata_copyright_openstreetmap_contributors.rds"))
train$Date <- as.Date(train$Date)
counts_by_date <- train %>% group_by(Date) %>% summarise(NumMeasurements = n()) %>% arrange(desc(NumMeasurements)) %>% head
counts_by_date
date_to_show <- counts_by_date$Date[1]
single_date_grouped_by_location <- train %>%
filter(Date == "2007-08-01") %>%
group_by(Longitude, Latitude) %>%
summarize(NumMosquitos = sum(NumMosquitos))
qplot(single_date_grouped_by_location$NumMosquitos) +
scale_x_log10() +
xlab("Number of Mosquitos") +
ylab("Number of test sites w/ this many mosquitos") +
ggtitle("Distribution of Mosquito Counts (Log Scale")
library(readr)
library(ggmap)
data_dir <- "../input"
train <- read_csv(file.path(data_dir, "train.csv"))
mapdata <- readRDS(file.path(data_dir, "mapdata_copyright_openstreetmap_contributors.rds"))
train$Date <- as.Date(train$Date)
counts_by_date <- train %>% group_by(Date) %>% summarise(NumMeasurements = n()) %>% arrange(desc(NumMeasurements)) %>% head
counts_by_date
date_to_show <- counts_by_date$Date[1]
library(readr)
library(ggmap)
data_dir <- "../input"
train <- read_csv(file.path(data_dir, "train.csv"))
mapdata <- readRDS(file.path(data_dir, "mapdata_copyright_openstreetmap_contributors.rds"))
train$Date <- as.Date(train$Date)
counts_by_date <- train %>% group_by(Date) %>% summarise(NumMeasurements = n()) %>% arrange(desc(NumMeasurements)) %>% head
counts_by_date
date_to_show <- counts_by_date$Date[1]
library(ggmap)
data_dir <- "../input"
train <- read_csv(file.path(data_dir, "train.csv"))
mapdata <- readRDS(file.path(data_dir, "mapdata_copyright_openstreetmap_contributors.rds"))
train$Date <- as.Date(train$Date)
counts_by_date <- train %>% group_by(Date) %>% summarise(NumMeasurements = n()) %>% arrange(desc(NumMeasurements)) %>% head
counts_by_date
date_to_show <- counts_by_date$Date[1]
single_date_grouped_by_location <- train %>%
filter(Date == "2007-08-01") %>%
group_by(Longitude, Latitude) %>%
summarize(NumMosquitos = sum(NumMosquitos))
qplot(single_date_grouped_by_location$NumMosquitos) +
scale_x_log10() +
xlab("Number of Mosquitos") +
ylab("Number of test sites w/ this many mosquitos") +
ggtitle("Distribution of Mosquito Counts (Log Scale")
ggmap(mapdata) +
geom_point(aes(x=Longitude, y=Latitude, color=NumMosquitos), size=3, data=single_date_grouped_by_location) +
scale_color_continuous(trans="log") +
citation()
getwd(0)
getwd()
setwd("./Desktop/Analytics Edge/Unit 7/")
library(ggplot2)
library(maps)
library(ggmap)
statesMap = map_data("state")
str(statesMap)
table(statesMap$group)
ggplot(statesMap, aes(x = long, y = lat, group = group)) + geom_polygon(fill = "white", color = "black")
ggplot(statesMap, aes(x = long, y = lat, group = group)) + geom_polygon(fill = "white", color = "red")
ggplot(statesMap, aes(x = long, y = lat, group = group)) + geom_polygon(fill = "white", color = "black")
polling = read.csv("./PollingImputed")
polling = read.csv("./PollingImputed.csv")
str(polling)
Train = subset(polling, Year == 2004 | Year == 2008)
Test = subset(polling, Year == 2012)
mod2 = glm(Republican~SurveyUSA+DiffCount, data=Train, family="binomial")
summary(mod2)
TestPrediction = predict(mod2, newdata=Test, type="response")
TestPrediction
TestPredictionBinary = as.numeric(TestPrediction > 0.5)
head(TestPrediction)
str(TestPrediction)
str(TestPredictionBinary)
predictionDataFrame = data.frame(TestPrediction, TestPredictionBinary, Test$State)
predictionDataFrame
table(predictionDataFrame)
str(predictionDataFrame)
table(predictionDataFrame$TestState)
table(predictionDataFrame)
table(predictionDataFrame$Test.State)
table(predictionDataFrame$Test.State=1)
table(predictionDataFrame$Test.State==1)
str(predictionDataFrame)
summary(predictionDataFrame)
table(predictionDataFrame$Test.State)
table(predictionDataFrame$Test.State==0)
tapply(predictionDataFrame$Test.State==0)
which(predictionDataFrame$Test.State==1)
count(predictionDataFrame$Test.State==1)
summary(predictionDataFrame$Test.State==1)
table(TestPrediction)
summary(TestPrediction)
str(TestPrediction)
str(predictionDataFrame)
summary(predictionDataFrame$TestPredictionBinary==1)
table(predictionDataFrame$TestPredictionBinary==1)
TestPredictionBinary = as.numeric(TestPrediction > 0.5)
predictionDataFrame$region = tolower(predictionDataFrame$Test.State)
predictionMap = merge(statesMap, predictionDataFrame, by = "region")
predictionMap
str(predictionMap)
str(statesMap)
?merge
table(statesMap$region)
summary(statesMap$region)
str(statesMap$region)
table(predictionMap$region)
str(predictionDataFrame)
str(statesMap)
ggplot(predictionMap, aes(x = long, y = lat, group = group, fill = TestPredictionBinary)) + geom_polygon(color = "black")
ggplot(predictionMap, aes(x = long, y = lat, group = group, fill = TestPredictionBinary))+ geom_polygon(color = "black") + scale_fill_gradient(low = "blue", high = "red", guide = "legend", breaks= c(0,1), labels = c("Democrat", "Republican"), name = "Prediction 2012")
ggplot(predictionMap, aes(x = long, y = lat, group = group, fill = TestPrediction))+ geom_polygon(color = "black") + scale_fill_gradient(low = "blue", high = "red", guide = "legend", breaks= c(0,1), labels = c("Democrat", "Republican"), name = "Prediction 2012")
ggplot(predictionMap, aes(x = long, y = lat, group = group, fill = TestPrediction)) + geom_polygon(color = "black")
ggplot(predictionMap, aes(x = long, y = lat, group = group, fill = TestPrediction)) + geom_polygon(color = "red")
ggplot(predictionMap, aes(x = long, y = lat, group = group, fill = TestPrediction)) + geom_polygon(color = "black")
ggplot(predictionMap, aes(x = long, y = lat, group = group, fill = TestPrediction))+ geom_polygon(color = "black") + scale_fill_gradient(low = "blue", high = "red", guide = "legend", breaks= c(0,1), labels = c("Democrat", "Republican"), name = "Prediction 2012")
summary(predictionMap)
predictionMap$Test.State==Florida
table(predictionMap$Test.State==Florida)
predictionMap
str(predictionMap$Test.State
str(predictionMap$Test.State)
summary(predictionDataFrame)
summary(predictionDataFrame$Test.State==Florida)
summary(predictionDataFrame$Test.State=="Florida")
predictionDataFrame$Test.State=="Florida"
table(predictionDataFrame$Test.State=="Florida")
which(predictionDataFrame$Test.State=="Florida")
predictionDataFrame$Test.State[6]
predictionDataFrame[6]
predictionDataFrame
predictionDataFrame$TestPrediction[6]
predictionDataFrame$Test.State=="Florida"
which(predictionDataFrame$Test.State=="Florida")
# ?geom_polygon()
?geom_polygon()
ggplot(predictionMap, aes(x = long, y = lat, group = group, fill = TestPredictionBinary))+ geom_polygon(color = "black") + scale_fill_gradient(low = "blue", high = "red", guide = "legend", breaks= c(0,1), labels = c("Democrat", "Republican"), name = "Prediction 2012")
egdes = read.csv("./edges.csv")
users = read.csv("./users.csv")
str(users)
table(users$id)
str(edges)
edges = read.csv("./edges.csv")
str(edges)
summary(users)
summary(edges)
table(users$locale)
str(edges)
146/59
table(edges$V1)
tapply(edges$V1, mean)
tapply(edges$V1, edges$V2, mean)
tapply(edges$V1, users$id, mean)
which.mean(edges$V1,mean)
which.mean(edges$V1)
which(edges$V1)
table(edges$V1)
3 + 7 + 13 + 1 + 5 + 7 + 1 + 4 + 4 + 3 + 1 + 2 + 3 + 8 + 5 + 2 + 7 + 9 + 2 + 5 + 1 + 4 + 3 + 6 + 1 + 2 + 3 + 1 + 3 + 6 + 1 + 3 + 2 + 2 + 5 + 2 + 4 + 1 + 3 + 1
146/40
str(users)
table(users$school)
table(users$gender, users$school)
install.packages(igraphs)
install.packages(igraph)
install.packages("igraph")
library(igraph)
?igraph()
g.graph.data.frame(edges, FALSE, users)
g = graph.data.frame(edges, FALSE, users)
g = graph.data.frame(uders, FALSE, edges)
g = graph.data.frame(users, FALSE, edges)
g = graph.data.frame(edges, TRUE, users)
g = graph.data.frame(users, TRUE, edges)
?graph.data.frame(0)
g = graph.data.frame(edges, FALSE, users)
?graph.data.frame()
g = graph.data.frame(edges, FALSE, users)
plot(g, vertex.size=5, vertex.label=NA)
degree(g)
V(g)$size = degree(g)/2+2
plot(g, vertex.label=NA)
V(g)$size
V(g)$color = "black"
V(g)$color[V(g)$gender == "A"] = "red"
V(g)$color[V(g)$gender == "B"] = "gray"
plot(g, vertex.label=NA)
V(g)$color[V(g)$school == "A"] = "red"
V(g)$color[V(g)$school == "AB"] = "gray"
plot(g, vertex.label=NA)
V(g)$color[V(g)$locale == "A"] = "red"
V(g)$color[V(g)$locale == "B"] = "gray"
plot(g, vertex.label=NA)
?igraph.plotting
tweets = read.csv("./tweets.csv", stringsAsFactors=FALSE)
tweets = read.csv("./tweets.csv", stringsAsFactors=FALSE)
str(tweets)
install.packages("tm")
library(tm)
install.packages("SnowballC")
library(SnowballC)
corpus = Corpus(VectorSource(tweets$Tweet))
corpus = tm_map(corpus, tolower)
corpus[[1]]
corpus = tm_map(corpus, PlainTextDocument)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords, c("apple", stopwords("english")))
frequencies = DocumentTermMatrix(corpus)
allTweets = DocumentTermMatrix(corpus)
str(allTweets)
allTweets
install.packages("wordcloud")
library(wordcloud)
library(RColorBrewer)
?wordcloud
r  = rownames(allTweets)
r
c = colnames(allTweets)
c
f = colSums(allTweets)
f
f = rowSums(allTweets)
f = sum(allTweets)
f
f = colSums(c)
f = rowSums(c)
f = sums(c)
f = sum(c)
colSums(allTweets)
allTweets # unique words == terms
colSums(allTweets)
tweets = read.csv("./tweets.csv", stringsAsFactors=FALSE)
str(tweets)
corpus = Corpus(VectorSource(tweets$Tweet))
corpus = tm_map(corpus, tolower)
corpus = tm_map(corpus, PlainTextDocument)
corpus = tm_map(corpus, removePunctuation)
corpus = tm_map(corpus, removeWords,stopwords("english"))
allTweets = DocumentTermMatrix(corpus)
allTweets # unique words == terms
corpus = tm_map(corpus, removeWords, c("apple", stopwords("english")))
allTweets = DocumentTermMatrix(corpus)
allTweets # unique words == terms
c = colnames(allTweets)
f = sum(allTweets)
f = colSums(allTweets)
colnames(allTweets)
colSums(allTweets)
allTweets
which.max(allTweets$Weighting)
allTweets$Weighting
corpus = tm_map(corpus, removeWords, c("apple", stopwords("english")))
allTweets = DocumentTermMatrix(corpus)
allTweets # unique words == terms
?RColorBrewer
colors=brewer.pal(9, "Blues")
colors
wordcloud(colnames(allTweets),scale=c(1,0.2))
